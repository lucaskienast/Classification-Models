{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3) Multi-Class PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIDCOSGQDvKI"
      },
      "source": [
        "# Multi-Class Classification: PyTorch Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqTKwxsqD602"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKmGLtQvDmi6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxC142k6Ev01"
      },
      "source": [
        "## Define transform for images to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmw3CO6tENtR"
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_H0O5-sE8QZ"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0S8SR5nE9n4",
        "outputId": "1820d75c-42a6-43b9-bfd8-d2ec74f7eb27"
      },
      "source": [
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PumNYoxCFO8b"
      },
      "source": [
        "## Create image-show function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxmpgdzEENqr"
      },
      "source": [
        "# function to show Fashion MNIST images\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcNfuBj1FVIj"
      },
      "source": [
        "## Show example image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "b5RK51ZqENoR",
        "outputId": "ff3e8220-a72f-4a9c-e3df-12a39b26692a"
      },
      "source": [
        "# show an image of the dataset as an example\n",
        "image, label = next(iter(trainloader))\n",
        "print(label[0])\n",
        "print(image[0].shape)\n",
        "imshow(image[0, :])\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4)\n",
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znx0MFN3GG_j"
      },
      "source": [
        "## Build and train network\n",
        "\n",
        "As with MNIST, each image is 28x28 which is a total of 784 pixels, and there are 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko8gNierENlm"
      },
      "source": [
        "# build network \n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEaVAD9UENjI"
      },
      "source": [
        "# define model\n",
        "model = Classifier()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU8ODWj6Hqmc"
      },
      "source": [
        "# define loss function\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh9oJ5R5H1Kr"
      },
      "source": [
        "# define optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9oSkjspH8Wr",
        "outputId": "04945334-49e6-4a4e-e18f-110486c39ea7"
      },
      "source": [
        "#train network\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Step 0: reset gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Step 1: make prediction\n",
        "        log_ps = model(images)\n",
        "        # Step 2: compute loss\n",
        "        loss = criterion(log_ps, labels)\n",
        "        # Step 3: compute grad of loss wrt. weights and bias\n",
        "        loss.backward()\n",
        "        # Step 4: adjust weights and bias via gradient descent\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.5067157535982538\n",
            "Training loss: 0.3893512786785041\n",
            "Training loss: 0.35531173455022547\n",
            "Training loss: 0.33312828455175925\n",
            "Training loss: 0.3172086393480489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp5MmpfUJptE"
      },
      "source": [
        "## Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUqmg9uwKS9e"
      },
      "source": [
        "# function to show classification results\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "1cTrUPJHI-ZZ",
        "outputId": "d9ed6080-c6ed-413b-d301-35e907fb222d"
      },
      "source": [
        "# test example image\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "img = images[1]\n",
        "\n",
        "# TODO: Calculate the class probabilities (softmax) for img\n",
        "ps = torch.exp(model(img))\n",
        "\n",
        "# Plot the image and probabilities\n",
        "view_classify(img, ps, version='Fashion')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA3pE4m2KW5i",
        "outputId": "704a579f-b420-483e-b4d7-81f207e32c6d"
      },
      "source": [
        "# test on all test data\n",
        "correct_count, all_count = 0, 0\n",
        "for images, labels in testloader:\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1, 784)\n",
        "    with torch.no_grad():\n",
        "        logps = model(img)\n",
        "\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Images Tested = 10000\n",
            "\n",
            "Model Accuracy = 0.8703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FzDt6obKoEa"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}